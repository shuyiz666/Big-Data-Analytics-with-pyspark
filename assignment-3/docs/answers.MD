## Task1
m = 2.3743748579662416
b = 8.989846634766463
computation time: 54 min 51 sec

## Task2
iter: 1 cost: 11085052384.180817 m: 0.20075192778222234  b: 0.10736489030682282
m_gradient: -1007.5192778222233 b_gradient: -73.64890306822822
learningRate: 0.0001
iter: 2 cost: 10356633325.229565 m: 0.29798995878040735  b: 0.11448081410692665
m_gradient: -972.3803099818499 b_gradient: -71.15923800103826
learningRate: 0.000105
iter: 3 cost: 9678129941.38019 m: 0.3965289601916463  b: 0.1217002348985959
m_gradient: -938.4666801070377 b_gradient: -68.75638849208808
learningRate: 0.00011025000000000001
iter: 4 cost: 9015110062.168621 m: 0.4962058868654998  b: 0.12901216639460864
m_gradient: -904.0991081528666 b_gradient: -66.32137411349412
learningRate: 0.00011576250000000002
iter: 5 cost: 8369588300.74256 m: 0.5968422145153688  b: 0.13640455381702757
m_gradient: -869.3344360208959 b_gradient: -63.85822198396652
learningRate: 0.00012155062500000002
iter: 6 cost: 7743518979.6186285 m: 0.6982439883329215  b: 0.1438642787454374
m_gradient: -834.234902679872 b_gradient: -61.37134159869444
learningRate: 0.00012762815625000002
iter: 7 cost: 7138771471.223158 m: 0.8002020544915988  b: 0.15137717699244257
m_gradient: -798.8681271784591 b_gradient: -58.86552362543588
learningRate: 0.00013400956406250003
iter: 8 cost: 6557104914.762603 m: 0.9024924965437597  b: 0.1589280710688604
m_gradient: -763.3070278808927 b_gradient: -56.34593418195276
learningRate: 0.00014071004226562505
iter: 9 cost: 6000142794.306457 m: 1.0048772981986982  b: 0.1665008187645535
m_gradient: -727.6296702524037 b_gradient: -53.81810405114982
learningRate: 0.0001477455443789063
iter: 10 cost: 5469347932.413501 m: 1.1071052527943923  b: 0.17407837928782086
m_gradient: -691.919035700472 b_gradient: -51.287912303020356
learningRate: 0.00015513282159785162
iter: 11 cost: 4965998514.505378 m: 1.2089131378357716  b: 0.18164289826897073
m_gradient: -656.2627043894959 b_gradient: -48.76156382147973
learningRate: 0.0001628894626777442
iter: 12 cost: 4491165807.251306 m: 1.3100271701588848  b: 0.18917581273458312
m_gradient: -620.7524456210796 b_gradient: -46.24556028228343
learningRate: 0.0001710339358116314
iter: 13 cost: 4045694264.8705106 m: 1.4101647534945356  b: 0.19665797689090475
m_gradient: -585.4837103552218 b_gradient: -43.746664197461556
learningRate: 0.00017958563260221297
iter: 14 cost: 3630184725.887767 m: 1.5090365253605904  b: 0.20406980921182974
m_gradient: -550.5550217653464 b_gradient: -41.271855735488586
learningRate: 0.00018856491423232364
iter: 15 cost: 3244981385.1098156 m: 1.6063487042468274  b: 0.21139146090446242
m_gradient: -516.0672614118572 b_gradient: -38.82828214591367
learningRate: 0.00019799315994393983
iter: 16 cost: 2890163177.580367 m: 1.7018057309375842  b: 0.2186030053211403
m_gradient: -482.1228506973917 b_gradient: -36.42319976467749
learningRate: 0.00020789281794113683
iter: 17 cost: 2565540130.289158 m: 1.795113189556336  b: 0.2256846473017106
m_gradient: -448.82482975035214 b_gradient: -34.063908752131084
learningRate: 0.00021828745883819368
iter: 18 cost: 2270655121.942032 m: 1.8859809845756685  b: 0.2326169507683161
m_gradient: -416.27583876309046 b_gradient: -31.757680919929008
learningRate: 0.00022920183178010337
iter: 19 cost: 2004791341.6246552 m: 1.9741267397439586  b: 0.23938108216599613
m_gradient: -384.5770100688256 b_gradient: -29.51168123372392
learningRate: 0.00024066192336910856
iter: 20 cost: 1766985556.2861104 m: 2.059279373839629  b: 0.24595906656043603
m_gradient: -353.8267828312416 b_gradient: -27.332883832857522
learningRate: 0.000252695019537564
iter: 21 cost: 1556047089.761096 m: 2.141182796662254  b: 0.2523340523896069
m_gradient: -324.1196560680519 b_gradient: -25.227983681028597
learningRate: 0.0002653297705144422
iter: 22 cost: 1370582190.2966096 m: 2.219599657088099  b: 0.2584905800457286
m_gradient: -295.5448997442102 b_gradient: -23.203305246090533
learningRate: 0.0002785962590401643
iter: 23 cost: 1209023229.6126926 m: 2.294315063828537  b: 0.2644148486715574
m_gradient: -268.18524770523317 b_gradient: -21.264709893231924
learningRate: 0.0002925260719921725
iter: 24 cost: 1069661947.0567248 m: 2.365140189301571  b: 0.27009497483060796
m_gradient: -242.11560012650568 b_gradient: -19.417503952271804
learningRate: 0.00030715237559178114
iter: 25 cost: 950685741.8023927 m: 2.4319156584068575  b: 0.2755212361005524
m_gradient: -217.4017667180076 b_gradient: -17.66634967250328
learningRate: 0.0003225099943713702
iter: 26 cost: 850215839.504659 m: 2.494514617697846  b: 0.2806862921932169
m_gradient: -194.09928493225436 b_gradient: -16.015181491451447
learningRate: 0.0003386354940899387
iter: 27 cost: 766346032.2835902 m: 2.552845377218546  b: 0.28558537597639017
m_gradient: -172.25234961698422 b_gradient: -14.467130199506183
learningRate: 0.00035556726879443565
iter: 28 cost: 697180625.6144798 m: 2.606853517862744  b: 0.29021644681483316
m_gradient: -151.89289168070565 b_gradient: -13.024457662103737
learningRate: 0.00037334563223415747
iter: 29 cost: 640870232.7924986 m: 2.6565233622092665  b: 0.2945802990092913
m_gradient: -133.03984313219522 b_gradient: -11.688504746511086
learningRate: 0.00039201291384586537
iter: 30 cost: 595644142.6577764 m: 2.701878716962333  b: 0.2986806188336306
m_gradient: -115.69862407874537 b_gradient: -10.459654974406124
learningRate: 0.00041161355953815866
iter: 31 cost: 559838149.0601817 m: 2.742982810768721  b: 0.3025239847789033
m_gradient: -99.86088371944837 b_gradient: -9.337316170014056
learningRate: 0.0004321942375150666
iter: 32 cost: 531916964.36891705 m: 2.779937372421787  b: 0.3061198071183134
m_gradient: -85.50452191482009 b_gradient: -8.31992198712441
learningRate: 0.00045380394939081994
iter: 33 cost: 510490630.8000336 m: 2.812880821092594  b: 0.3094802047942294
m_gradient: -72.59401050834866 b_gradient: -7.404954673547788
learningRate: 0.00047649414686036094
iter: 34 cost: 494324672.8994711 m: 2.841985571650572  b: 0.31261981985510795
m_gradient: -61.081024289070655 b_gradient: -6.58898977367426
learningRate: 0.000500318854203379
iter: 35 cost: 482344077.9073074 m: 2.8674544933085313  b: 0.31555557216262486
m_gradient: -50.905380526807086 b_gradient: -5.867762693435395
learningRate: 0.000525334796913548
iter: 36 cost: 473631521.0704043 m: 2.8895165972486554  b: 0.31830635974111937
m_gradient: -41.996273747224464 b_gradient: -5.236256183020726
learningRate: 0.0005516015367592254
iter: 37 cost: 467420543.5019689 m: 2.9084220666161755  b: 0.32089271281513504
m_gradient: -34.273779363621436 b_gradient: -4.688806868108143
learningRate: 0.0005791816135971866
iter: 38 cost: 463084617.26190275 m: 2.924436777995243  b: 0.3233364121126609
m_gradient: -27.65058662619339 b_gradient: -4.219228028231956
learningRate: 0.000608140694277046
iter: 39 cost: 460123178.27325726 m: 2.9378364946453797  b: 0.32566008422015447
m_gradient: -22.033908890221618 b_gradient: -3.820944938170839
learningRate: 0.0006385477289908983
iter: 40 cost: 458145763.0900787 m: 2.948900935743524  b: 0.3278867884739957
m_gradient: -17.327508337755106 b_gradient: -3.487138318321346
learningRate: 0.0006704751154404432
iter: 41 cost: 456855350.5669339 m: 2.9579079401651107  b: 0.3300396108858914
m_gradient: -13.433763929732022 b_gradient: -3.21089084787506
learningRate: 0.0007039988712124654
iter: 42 cost: 456031893.9406922 m: 2.96512794588218  b: 0.33214128078058086
m_gradient: -10.255706382929933 b_gradient: -2.9853313416112073
learningRate: 0.0007391988147730887
iter: 43 cost: 455516850.81416917 m: 2.970818995481103  b: 0.3342138250754732
m_gradient: -7.698943078892849 b_gradient: -2.803771128243187
learningRate: 0.0007761587555117431
iter: 44 cost: 455199301.8409948 m: 2.975222454176274  b: 0.33627827342306216
m_gradient: -5.673399499652592 b_gradient: -2.6598274295415507
learningRate: 0.0008149666932873303
iter: 45 cost: 455004019.7077941 m: 2.9785595897330754  b: 0.33835442481869005
m_gradient: -4.0948121982023595 b_gradient: -2.54752913552001
learningRate: 0.0008557150279516969
iter: 46 cost: 454881633.1070278 m: 2.9810291158743425  b: 0.3404606828873966
m_gradient: -2.8859212011016804 b_gradient: -2.461401284196526
learningRate: 0.0008985007793492818
iter: 47 cost: 454800845.9747577 m: 2.982805745206119  b: 0.34261396312925246
m_gradient: -1.9773264226473697 b_gradient: -2.3965257363664585
learningRate: 0.000943425818316746
iter: 48 cost: 454742533.5376231 m: 2.9840397386639257  b: 0.3448296712205396
m_gradient: -1.3079920369451166 b_gradient: -2.3485769079760854
learningRate: 0.0009905971092325832
iter: 49 cost: 454695448.91634774 m: 2.9848573808267345  b: 0.34712174738391605
m_gradient: -0.825403340256104 b_gradient: -2.3138328812125537
learningRate: 0.0010401269646942125
iter: 50 cost: 454653234.8774104 m: 2.9853622592257523  b: 0.34950276821231635
m_gradient: -0.4854007406357623 b_gradient: -2.289163639844986
learningRate: 0.0010921333129289231
iter: 51 cost: 454612436.66730696 m: 2.9856371856282995  b: 0.3519840944874901
m_gradient: -0.2517333729249341 b_gradient: -2.271999439811233
learningRate: 0.0011467399785753693
iter: 52 cost: 454571242.1196271 m: 2.985746571820968  b: 0.3545760517310602
m_gradient: -0.09538883680038826 b_gradient: -2.260283317923766
learningRate: 0.0012040769775041379
iter: 53 cost: 454528721.96257645 m: 2.985739063717652  b: 0.3572881296102287
m_gradient: 0.006235567539304692 b_gradient: -2.2524123705032784
learningRate: 0.0012642808263793447
iter: 54 cost: 454484395.3960673 m: 2.985650245842543  b: 0.3601291869034603
m_gradient: 0.0702516982428928 b_gradient: -2.2471726486336334
learningRate: 0.001327494867698312
iter: 55 cost: 454437995.24924034 m: 2.9855052515625635  b: 0.36310765038452486
m_gradient: 0.10922398534826952 b_gradient: -2.243672313572688
learningRate: 0.0013938696110832277
iter: 56 cost: 454389348.38219047 m: 2.985321149274533  b: 0.36623169845148146
m_gradient: 0.1320799926811329 b_gradient: -2.2412771195497996
learningRate: 0.001463563091637389
iter: 57 cost: 454338318.5107311 m: 2.9851090162430034  b: 0.3695094232672325
m_gradient: 0.14494286767807546 b_gradient: -2.2395514306691435
learningRate: 0.0015367412462192586
iter: 58 cost: 454284780.62355185 m: 2.9848756545746693  b: 0.3729489682103114
m_gradient: 0.1518548870268321 b_gradient: -2.238206953539523
learningRate: 0.0016135783085302216
iter: 59 cost: 454228610.27303225 m: 2.9846249428644964  b: 0.376558640201516
m_gradient: 0.15537622738708243 b_gradient: -2.2370603100710964
learningRate: 0.0016942572239567327
iter: 60 cost: 454169679.34303284 m: 2.984358848403417  b: 0.38034699869371924
m_gradient: 0.1570567073976405 b_gradient: -2.235999610115846
learningRate: 0.0017789700851545695
iter: 61 cost: 454107854.40937626 m: 2.9840781461707495  b: 0.38432292462380413
m_gradient: 0.1577891809480565 b_gradient: -2.234959408965802
learningRate: 0.0018679185894122981
iter: 62 cost: 454042996.04522705 m: 2.9837829016493473  b: 0.3884956733919563
m_gradient: 0.15806070086542579 b_gradient: -2.2339029076556467
learningRate: 0.0019613145188829132
iter: 63 cost: 453974958.43466 m: 2.983472775962688  b: 0.3928749160370173
m_gradient: 0.15812134345292264 b_gradient: -2.2328099868221334
learningRate: 0.0020593802448270588
iter: 64 cost: 453903589.0729614 m: 2.983147206287172  b: 0.3974707723834837
m_gradient: 0.15809109382961484 b_gradient: -2.23166962876852
learningRate: 0.0021623492570684117
iter: 65 cost: 453828728.4835261 m: 2.98280550481239  b: 0.40229383924955037
m_gradient: 0.15802325811380735 b_gradient: -2.2304754194081893
learningRate: 0.0022704667199218323
iter: 66 cost: 453750209.93322456 m: 2.982446908450367  b: 0.4073552160206561
m_gradient: 0.15793949273808716 b_gradient: -2.2292230609220183
learningRate: 0.002383990055917924
iter: 67 cost: 453667859.1407467 m: 2.982070601150074  b: 0.4126665291594115
m_gradient: 0.1578476803453931 b_gradient: -2.227909099524454
learningRate: 0.0025031895587138203
iter: 68 cost: 453581493.9778668 m: 2.98167572231038  b: 0.41823995662935576
m_gradient: 0.1577502743726492 b_gradient: -2.226530328293636
learningRate: 0.0026283490366495114
iter: 69 cost: 453490924.16347706 m: 2.9812613688196503  b: 0.4240882527862675
m_gradient: 0.15764781806077355 b_gradient: -2.2250835316632287
learningRate: 0.002759766488481987
iter: 70 cost: 453395950.95080864 m: 2.980826594479616  b: 0.43022477402222375
m_gradient: 0.15754026358711484 b_gradient: -2.2235653855379804
learningRate: 0.0028977548129060864
iter: 71 cost: 453296366.8082231 m: 2.980370408467498  b: 0.4366635052968804
m_gradient: 0.15742740209989625 b_gradient: -2.2219724201577367
learningRate: 0.003042642553551391
iter: 72 cost: 453191955.0941871 m: 2.979891773465259  b: 0.443419087615816
m_gradient: 0.1573089818520396 b_gradient: -2.2203010048125447
learningRate: 0.0031947746812289604
iter: 73 cost: 453082489.72731763 m: 2.9793896036564806  b: 0.4505068464830502
m_gradient: 0.1571847340999693 b_gradient: -2.2185473388400982
learningRate: 0.0033545134152904088
iter: 74 cost: 452967734.85186386 m: 2.978862762641896  b: 0.4579428213414757
m_gradient: 0.15705437700234576 b_gradient: -2.2167074439264747
learningRate: 0.003522239086054929
iter: 75 cost: 452847444.49969345 m: 2.9783100612830715  b: 0.46574379600875515
m_gradient: 0.15691761556252948 b_gradient: -2.214777156430032
learningRate: 0.003698351040357676
iter: 76 cost: 452721362.25028163 m: 2.977730255475245  b: 0.47392733011188126
m_gradient: 0.1567741410966953 b_gradient: -2.2127521194782678
learningRate: 0.0038832685923755597
iter: 77 cost: 452589220.8893522 m: 2.9771220438495205  b: 0.4825117915192273
m_gradient: 0.15662363064937412 b_gradient: -2.210627774808275
learningRate: 0.0040774320219943375
iter: 78 cost: 452450742.06764525 m: 2.9764840654047937  b: 0.4915163897639965
m_gradient: 0.1564657464024518 b_gradient: -2.208399354347763
learningRate: 0.004281303623094055
iter: 79 cost: 452305635.9620404 m: 2.9758148970702982  b: 0.5009612104473836
m_gradient: 0.15630013505370677 b_gradient: -2.206061871538434
learningRate: 0.0044953688042487575
iter: 80 cost: 452153600.93996555 m: 2.9751130511999597  b: 0.5108672506034166
m_gradient: 0.156126427196574 b_gradient: -2.203610112405116
learningRate: 0.004720137244461195
iter: 81 cost: 451994323.22981626 m: 2.9743769730004836  b: 0.5212564550002784
m_gradient: 0.15594423665109378 b_gradient: -2.201038626377422
learningRate: 0.004956144106684255
iter: 82 cost: 451827476.5995139 m: 2.973605037895363  b: 0.5321517533447877
m_gradient: 0.15575315981622087 b_gradient: -2.1983417168631307
learningRate: 0.005203951312018468
iter: 83 cost: 451652722.04565644 m: 2.9727955488279716  b: 0.5435770983476762
m_gradient: 0.1555527749696585 b_gradient: -2.195513431592221
learningRate: 0.005464148877619392
iter: 84 cost: 451469707.4962544 m: 2.971946733507358  b: 0.5555575045970903
m_gradient: 0.1553426415759398 b_gradient: -2.192547552736825
learningRate: 0.005737356321500362
iter: 85 cost: 451278067.53049594 m: 2.9710567416012914  b: 0.5681190881763484
m_gradient: 0.1551222995739666 b_gradient: -2.189437586817531
learningRate: 0.00602422413757538
iter: 86 cost: 451077423.1186962 m: 2.9701236418820884  b: 0.5812891069493378
m_gradient: 0.15489126863370006 b_gradient: -2.186176754421044
learningRate: 0.006325435344454149
iter: 87 cost: 450867381.38701624 m: 2.9691454193314253  b: 0.5950960014227812
m_gradient: 0.15464904744002575 b_gradient: -2.182757979741064
learningRate: 0.006641707111676857
iter: 88 cost: 450647535.410594 m: 2.968119972211997  b: 0.6095694360789774
m_gradient: 0.15439511291089925 b_gradient: -2.1791738799728706
learningRate: 0.0069737924672607
iter: 89 cost: 450417464.0408185 m: 2.9670451091144074  b: 0.6247403410552351
m_gradient: 0.15412891947032925 b_gradient: -2.1754167545821526
learningRate: 0.007322482090623735
iter: 90 cost: 450176731.77137417 m: 2.96591854598988  b: 0.6406409540270771
m_gradient: 0.15384989824287612 b_gradient: -2.17147857448533
learningRate: 0.007688606195154922
iter: 91 cost: 449924888.64918303 m: 2.964737903179769  b: 0.6573048621311605
m_gradient: 0.15355745633772666 b_gradient: -2.1673509711791907
learningRate: 0.00807303650491267
iter: 92 cost: 449661470.23671496 m: 2.9635007024561784  b: 0.6747670437405628
m_gradient: 0.15325097599123388 b_gradient: -2.16302522585847
learningRate: 0.008476688330158303
iter: 93 cost: 449385997.63277006 m: 2.962204364087003  b: 0.693063909879472
m_gradient: 0.15292981394198354 b_gradient: -2.158492258564307
learningRate: 0.00890052274666622
iter: 94 cost: 449097977.55875987 m: 2.9608462039455805  b: 0.7122333450365517
m_gradient: 0.1525933004251262 b_gradient: -2.153742617450173
learningRate: 0.00934554888399953
iter: 95 cost: 448796902.51958174 m: 2.9594234306784024  b: 0.7323147471050026
m_gradient: 0.15224073886274825 b_gradient: -2.148766468155999
learningRate: 0.009812826328199508
iter: 96 cost: 448482251.0474394 m: 2.9579331429641873  b: 0.7533490661450988
m_gradient: 0.15187140425918727 b_gradient: -2.1435535835021455
learningRate: 0.010303467644609484
iter: 97 cost: 448153488.0384846 m: 2.9563723268626996  b: 0.7753788416258445
m_gradient: 0.15148454436156694 b_gradient: -2.138093333293585
learningRate: 0.01081864102683996
iter: 98 cost: 447810065.1925154 m: 2.954737853342277  b: 0.7984482377689909
m_gradient: 0.1510793746060533 b_gradient: -2.132374674962743
learningRate: 0.011359573078181959
iter: 99 cost: 447451421.56733906 m: 2.9530264758554154  b: 0.8226030765598379
m_gradient: 0.15065508845121756 b_gradient: -2.1263861436166653
learningRate: 0.011927551732091058
iter: 100 cost: 447076984.25918937 m: 2.9512348284447425  b: 0.8478908679858951
m_gradient: 0.15021082707631295 b_gradient: -2.120115845569586
learningRate: 0.012523929318695611


## Task3
iter: 1 cost: 13796446906.808815 m: [2.69973074 1.21238316 3.59750959 0.11445363]  b: 0.1827756500542096
m_gradient: [-2599.73074412 -1112.38316086 -3497.50959395   -14.45363191] b_gradient: -82.7756500542096
learningRate: 0.001
iter: 2 cost: 270493157743.00345 m: [ -9.31532856  -3.7715396  -11.86984261   0.05374888]  b: -0.18232716695987417
m_gradient: [12015.05930009  4983.92276354 15467.35220457    60.70474708] b_gradient: 365.10281701408377
learningRate: 0.0005
iter: 3 cost: 5455715277762.523 m: [17.53534157  7.4324923  22.99801386  0.19239405]  b: 0.6415529719658541
m_gradient: [-53701.3402491  -22408.0637989  -69735.71295087   -277.2903306 ] b_gradient: -1647.7602778514565
learningRate: 0.00025
iter: 4 cost: 16650866583736.74 m: [-5.95205924 -2.3537734  -7.43460891  0.07187007]  b: -0.07724424395024043
m_gradient: [ 93949.6032251   39145.06280108 121730.49111197    482.09591291] b_gradient: 2875.1888636643785
learningRate: 0.000125
iter: 5 cost: 2323345472618.2915 m: [-1.57332997 -0.52599622 -1.74509032  0.09452813]  b: 0.05721788168237513
m_gradient: [-35029.83411314 -14622.21744354 -45516.14875676   -181.26444508] b_gradient: -1075.6970050609245
learningRate: 0.00013125000000000002
iter: 6 cost: 228260341115.98682 m: [-0.13711528  0.07520247  0.12924837  0.10205939]  b: 0.10155860867845046
m_gradient: [-10942.58811018  -4580.56150604 -14280.67572594    -57.38107795] b_gradient: -337.83411044628815
learningRate: 0.00013781250000000002
iter: 7 cost: 18053803049.970097 m: [0.27916959 0.25129534 0.68145261 0.10435235]  b: 0.11467142557344959
m_gradient: [-3020.66121045 -1277.77138489 -4006.92419333   -16.63819454] b_gradient: -95.14969175509569
learningRate: 0.00014470312500000003
iter: 8 cost: 1366203658.5741603 m: [0.38063763 0.29622415 0.8258566  0.10503385]  b: 0.11815600492182468
m_gradient: [-701.21529919 -310.48955462 -997.93277224   -4.70966424] b_gradient: -24.080885249541744
learningRate: 0.00015193828125000005
iter: 9 cost: 361439614.2878863 m: [0.39739555 0.30591324 0.8608472  0.10528777]  b: 0.1190615457590119
m_gradient: [-110.29422565  -63.76986127 -230.29480698   -1.67119726] b_gradient: -5.959925502232288
learningRate: 0.00015953519531250007
iter: 10 cost: 315588008.8552451 m: [0.39478937 0.30760235 0.87116309 0.1054506 ]  b: 0.11939027592755369
m_gradient: [ 16.33605514 -10.58771465 -64.66215584  -1.02066387] b_gradient: -2.0605495100806417
learningRate: 0.00016751195507812508
iter: 11 cost: 311246064.99016863 m: [0.38847424 0.30781606 0.87710702 0.1056033 ]  b: 0.11962229005104015
m_gradient: [ 37.69957758  -1.27577192 -35.48362699  -0.91155393] b_gradient: -1.3850600894620002
learningRate: 0.00017588755283203135
iter: 12 cost: 308023751.4928294 m: [0.38147185 0.30781193 0.88259853 0.10576185]  b: 0.11985069988721513
m_gradient: [ 3.98117783e+01  2.34797782e-02 -3.12217261e+01 -9.01478034e-01] b_gradient: -1.29861284950104
learningRate: 0.00018468193047363292
iter: 13 cost: 304780977.10761505 m: [0.37421836 0.3077692  0.88820311 0.105929  ]  b: 0.12008942412486238
m_gradient: [ 39.27554649   0.23132593 -30.34719415  -0.90504497] b_gradient: -1.2926236856796676
learningRate: 0.00019391602699731457
iter: 14 cost: 301505351.2020455 m: [0.36675551 0.30770216 0.8939732  0.10610545]  b: 0.12034030426379537
m_gradient: [ 38.48499579   0.34575836 -29.75561873  -0.9099411 ] b_gradient: -1.2937565956653028
learningRate: 0.00020361182834718032
iter: 15 cost: 298202795.2974138 m: [0.3590869  0.30760859 0.8999102  0.10629176]  b: 0.1206040207013572
m_gradient: [ 37.66285968   0.45953071 -29.15841196  -0.91502036] b_gradient: -1.2951921295661106
learningRate: 0.00021379241976453935
iter: 16 cost: 294879815.0689371 m: [0.35121547 0.3074854  0.90601277 0.1064885 ]  b: 0.1208812372159089
m_gradient: [ 36.81809121   0.57622372 -28.54438227  -0.92023608] b_gradient: -1.2966620372088786
learningRate: 0.0002244820407527663
iter: 17 cost: 291543369.8519538 m: [0.34314515 0.30732923 0.91227895 0.10669628]  b: 0.12117265311609826
m_gradient: [ 35.95085226   0.69569522 -27.91393774  -0.92558666] b_gradient: -1.2981702198186291
learningRate: 0.00023570614279040463
iter: 18 cost: 288200850.4576677 m: [0.33488092 0.30713645 0.91870603 0.10691574]  b: 0.12147900403279846
m_gradient: [ 35.06157262   0.81785211 -27.26735486  -0.93106895] b_gradient: -1.2997154553270045
learningRate: 0.0002474914499299249
iter: 19 cost: 284860049.4580021 m: [0.3264289  0.30690317 0.92529055 0.10714756]  b: 0.12180106384130246
m_gradient: [ 34.15078397   0.94257669 -26.6050093   -0.93667915] b_gradient: -1.30129670578596
learningRate: 0.00025986602242642116
iter: 20 cost: 281529123.2845267 m: [0.31779637 0.30662519 0.93202819 0.10739246]  b: 0.12213964656877145
m_gradient: [ 33.21914238   1.06973164 -25.92736223  -0.94241261] b_gradient: -1.3029126482468671
learningRate: 0.0002728593235477422
iter: 21 cost: 278216545.7129692 m: [0.3089919  0.30629799 0.93891378 0.1076512 ]  b: 0.12249560840035757
m_gradient: [ 32.26743344   1.19915789 -25.23496856  -0.94826388] b_gradient: -1.3045617315101274
learningRate: 0.00028650228972512936
iter: 22 cost: 274931052.4294414 m: [0.30002536 0.30591675 0.94594125 0.10792459]  b: 0.12286984976638551
m_gradient: [ 31.29657982   1.33067368 -24.52848144  -0.95422657] b_gradient: -1.3062421469196153
learningRate: 0.00030082740421138586
iter: 23 cost: 271681576.5310119 m: [0.29090799 0.30547631 0.95310355 0.10821347]  b: 0.12326331751750805
m_gradient: [ 30.30764773   1.4640735  -23.80865714  -0.96029338] b_gradient: -1.3079518209253491
learningRate: 0.0003158687744219552
iter: 24 cost: 268477175.0028114 m: [0.28165245 0.3049712  0.96039265 0.10851874]  b: 0.12367700718792958
m_gradient: [ 29.30185294   1.5991271  -23.07635929  -0.96645603] b_gradient: -1.309688402022634
learningRate: 0.00033166221314305294
iter: 25 cost: 265326946.43686795 m: [0.27227285 0.30439557 0.96779951 0.10884135]  b: 0.12411196534923048
m_gradient: [ 28.28056581   1.73557874 -22.33256256  -0.97270521] b_gradient: -1.3114492518726866
learningRate: 0.0003482453238002056
iter: 26 cost: 262239940.51330608 m: [0.2627848  0.30374326 0.97531408 0.1091823 ]  b: 0.1245692920561759
m_gradient: [ 27.24531546   1.87314651 -21.57835567  -0.9790306 ] b_gradient: -1.313231436835554
learningRate: 0.00036565758999021594
iter: 27 cost: 259225060.04957986 m: [0.25320538 0.30300773 0.98292522 0.10954262]  b: 0.12505014338656342
m_gradient: [ 26.19779264   2.01152187 -20.81494343  -0.98542082] b_gradient: -1.3150317224384713
learningRate: 0.00038394046948972676
iter: 28 cost: 256290956.7335316 m: [0.24355317 0.30218211 0.99062079 0.10992344]  b: 0.1255557340768245
m_gradient: [ 25.1398512    2.15036945 -20.04364781  -0.99186339] b_gradient: -1.3168465698159384
learningRate: 0.0004031374929642131
iter: 29 cost: 253445921.98413637 m: [0.23384824 0.3012592  0.99838759 0.11032591]  b: 0.12608734025557217
m_gradient: [ 24.07350792   2.28932707 -19.26590782  -0.99834482] b_gradient: -1.3186721355011135
learningRate: 0.0004232943676124238
iter: 30 cost: 250697774.72058615 m: [0.22411207 0.30023144 1.00621146 0.11075126]  b: 0.1266463022772338
m_gradient: [ 23.00094041   2.42800609 -18.483278    -1.00485051] b_gradient: -1.3205042741637354
learningRate: 0.000444459085993045
iter: 31 cost: 248053748.1537604 m: [0.21436753 0.29909096 1.01407724 0.11120077]  b: 0.12723402765853098
m_gradient: [ 21.92448293   2.56599212 -17.69742543  -1.01136487] b_gradient: -1.3223385454794792
learningRate: 0.0004666820402926973
iter: 32 cost: 245520378.029635 m: [0.20463879 0.29782959 1.0219689  0.11167579]  b: 0.1278519941206957
m_gradient: [ 20.84661982   2.70284601 -16.910125    -1.0178713 ] b_gradient: -1.324170224714777
learningRate: 0.0004900161423073322
iter: 33 cost: 243103395.03476253 m: [0.19495118 0.29643887 1.02986955 0.11217774]  b: 0.12850175274131326
m_gradient: [ 19.76997646   2.83810539 -16.12325288  -1.02435228] b_gradient: -1.3259943183872616
learningRate: 0.0005145169494226988
iter: 34 cost: 240807624.30070284 m: [0.1853311  0.2949101  1.03776161 0.1127081 ]  b: 0.12918493121985491
m_gradient: [ 18.69730735   2.97128655 -15.338778    -1.03078944] b_gradient: -1.3278055840691179
learningRate: 0.0005402427968938337
iter: 35 cost: 238636895.0968099 m: [0.17580582 0.29323432 1.04562687 0.11326842]  b: 0.12990323726276412
m_gradient: [ 17.63148133   3.10188684 -14.55875135  -1.03716364] b_gradient: -1.3295985564993382
learningRate: 0.0005672549367385254
iter: 36 cost: 236593963.85845026 m: [0.16640331 0.29140244 1.05344665 0.11386032]  b: 0.13065846209357881
m_gradient: [ 16.57546374   3.2293875  -13.78529318  -1.04345507] b_gradient: -1.3313675772606188
learningRate: 0.0005956176835754517
iter: 37 cost: 234680453.64049673 m: [0.157152   0.28940518 1.06120193 0.11448551]  b: 0.1314524840976249
m_gradient: [ 15.53229538   3.35325711 -13.02057792  -1.04964344] b_gradient: -1.333106833362673
learningRate: 0.0006253985677542243
iter: 38 cost: 232896812.8963504 m: [0.14808055 0.2872332  1.06887358 0.11514575]  b: 0.13228727260680406
m_gradient: [ 14.5050684    3.47295544 -12.26681659  -1.05570807] b_gradient: -1.3348103948764374
learningRate: 0.0006566684961419355
iter: 39 cost: 231242296.14708295 m: [0.13921756 0.28487711 1.0764425  0.11584289]  b: 0.1331648918437779
m_gradient: [ 13.4968988    3.58793781 -11.52623763  -1.06162811] b_gradient: -1.336472271975919
learningRate: 0.0006895019209490323
iter: 40 cost: 229714968.61603957 m: [0.13059127 0.28232757 1.08388985 0.11657885]  b: 0.13408750501821923
m_gradient: [ 12.51089678   3.69766021 -10.8010641   -1.06738268] b_gradient: -1.338086445316121
learningRate: 0.000723977016996484
iter: 41 cost: 228311736.26151198 m: [0.12222924 0.27957531 1.09119731 0.11735564]  b: 0.13505737864284725
m_gradient: [ 11.55013195   3.8015839  -10.09349237  -1.07295115] b_gradient: -1.3396469803028779
learningRate: 0.0007601758678463082
iter: 42 cost: 227028401.8537385 m: [0.114158   0.27661124 1.09834727 0.11817535]  b: 0.13607688693806302
m_gradient: [10.61760283  3.89918325 -9.40566008 -1.07831328] b_gradient: -1.3411479347590904
learningRate: 0.0007981846612386237
iter: 43 cost: 225859746.8331598 m: [0.10640269 0.27342653 1.10532311 0.11904014]  b: 0.13714851679292406
m_gradient: [ 9.71618483  3.98994566 -8.7396383  -1.08344959] b_gradient: -1.342583874260481
learningRate: 0.000838093894300555
iter: 44 cost: 224799637.68722358 m: [0.0989867  0.27001264 1.11210945 0.11995227]  b: 0.13827487185133336
m_gradient: [ 8.84863738  4.07339705 -8.09734401 -1.08834131] b_gradient: -1.3439485313865918
learningRate: 0.0008799985890155827
iter: 45 cost: 223841154.53731173 m: [0.09193139 0.26636149 1.11869246 0.12091409]  b: 0.13945868079265358
m_gradient: [ 8.01741054  4.14904412 -7.48071138 -1.09297147] b_gradient: -1.3452395902640126
learningRate: 0.000923998518466362
iter: 46 cost: 222976738.5904485 m: [0.08525535 0.26246535 1.12505969 0.12192801]  b: 0.14070279109201944
m_gradient: [ 7.2251566   4.21661052 -6.890949   -1.0973223 ] b_gradient: -1.346441876801707
learningRate: 0.0009701984443896801
iter: 47 cost: 222198354.14615473 m: [0.07897566 0.25831759 1.13120225 0.12299657]  b: 0.14201022267381586
m_gradient: [ 6.47258644  4.27516544 -6.33124243 -1.10138629] b_gradient: -1.3475919172586066
learningRate: 0.0010187083666091641
iter: 48 cost: 221497660.0344855 m: [0.07310076 0.25390994 1.13710628 0.12412237]  b: 0.1433839663749884
m_gradient: [ 5.76701301  4.3267064  -5.79560275 -1.10512231] b_gradient: -1.3485151847187902
learningRate: 0.0010696437849396223
iter: 49 cost: 220866184.98394778 m: [0.06766155 0.24924561 1.14279373 0.12530823]  b: 0.14482795049152752
m_gradient: [ 5.08506562  4.36063511 -5.31714882 -1.10864742] b_gradient: -1.3499672852496563
learningRate: 0.0011231259741866036
iter: 50 cost: 220295507.03612432 m: [0.06255712 0.24427517 1.14812276 0.12655642]  b: 0.14634232827164306
m_gradient: [ 4.54484367  4.42554064 -4.74481553 -1.11135147] b_gradient: -1.3483596808561764
learningRate: 0.0011792822728959337
iter: 51 cost: 219777602.68834233 m: [0.05835954 0.23923216 1.15383162 0.12787279]  b: 0.14794814372299578
m_gradient: [ 3.55942876  4.27633566 -4.84095801 -1.11625075] b_gradient: -1.3616887900886907
learningRate: 0.0012382463865407306
iter: 52 cost: 219310668.99229717 m: [0.05184698 0.23277107 1.1557465  0.12924383]  b: 0.14955050991611674
m_gradient: [ 5.25950794  5.21793689 -1.54644845 -1.10724186] b_gradient: -1.2940608674800769
learningRate: 0.001300158705867767
iter: 53 cost: 219093810.20609447 m: [0.06231048 0.23293398 1.17889399 0.13077193]  b: 0.1517444545479193
m_gradient: [ -8.04786874  -0.12529954 -17.80358521  -1.17532067] b_gradient: -1.6874437112185035
learningRate: 0.0013651666411611555
iter: 54 cost: 226989388.55750448 m: [-0.03277696  0.1886455   1.06441083  0.13183026]  b: 0.15078110774121717
m_gradient: [69.65263041 32.44181388 83.86020667 -0.77523482] b_gradient: 0.7056624280554794
learningRate: 0.0006825833205805778
iter: 55 cost: 578387332.4492364 m: [0.26398468 0.30993162 1.45307412 0.13412985]  b: 0.1608382628705092
m_gradient: [-434.76252152 -177.68690617 -569.40051468   -3.3689508 ] b_gradient: -14.733959688229458
learningRate: 0.0003412916602902889
iter: 56 cost: 2943045486.19124 m: [-0.14666432  0.1375108   0.9223855   0.13240437]  b: 0.1487408254749775
m_gradient: [1203.22014102  505.20078459 1554.94167725    5.05573371] b_gradient: 35.446038690901815
learningRate: 0.00017064583014514444
iter: 57 cost: 2304646048.2141957 m: [0.03241948 0.21154534 1.15548041 0.13351866]  b: 0.15446697861780975
m_gradient: [-1049.4472715   -433.84907701 -1365.95729191    -6.52988076] b_gradient: -33.5557753621159
learningRate: 0.00017917812165240166
iter: 58 cost: 225922239.81588572 m: [0.04386619 0.21566341 1.171228   0.13378043]  b: 0.1550698614699101
m_gradient: [-63.8845066  -22.983119   -87.88788168  -1.46091204] b_gradient: -3.364712424376825
learningRate: 0.00018813702773502175
iter: 59 cost: 217740295.17758727 m: [0.04373169 0.21491864 1.17198815 0.13399275]  b: 0.15533038194801715
m_gradient: [ 0.71492071  3.95868648 -4.04042582 -1.12857956] b_gradient: -1.3847379287504562
learningRate: 0.00019754387912177286
iter: 60 cost: 217693736.26105794 m: [0.04338934 0.21405036 1.17250913 0.13421465]  b: 0.15559753334362358
m_gradient: [ 1.73299446  4.39533861 -2.63727383 -1.12324941] b_gradient: -1.3523648355702793
learningRate: 0.0002074210730778615
iter: 61 cost: 217647416.25104854 m: [0.04304605 0.21314285 1.17305941 0.13444769]  b: 0.15587828414881458
m_gradient: [ 1.65504648  4.3752312  -2.652946   -1.12355059] b_gradient: -1.3535307720909138
learningRate: 0.00021779212673175458
iter: 62 cost: 217599312.80829343 m: [0.04269395 0.21219072 1.17362891 0.13469241]  b: 0.15617305475928805
m_gradient: [ 1.61670088  4.37174485 -2.61488441 -1.12364207] b_gradient: -1.3534493413370068
learningRate: 0.00022868173306834233
iter: 63 cost: 217549370.4930976 m: [0.04233413 0.21119223 1.1742191  0.1349494 ]  b: 0.15648257197154233
m_gradient: [ 1.57343924  4.36628731 -2.58084639 -1.12375244] b_gradient: -1.3534846360543573
learningRate: 0.00024011581972175947
iter: 64 cost: 217497535.08228913 m: [0.04196682 0.21014516 1.17483022 0.13521925]  b: 0.1568075689291229
m_gradient: [ 1.52971399  4.36067691 -2.54509887 -1.1238584 ] b_gradient: -1.3535008145534702
learningRate: 0.00025212161070784747
iter: 65 cost: 217443751.3695971 m: [0.04159246 0.20904727 1.17546269 0.13550263]  b: 0.15714882050450873
m_gradient: [ 1.48483474  4.35458378 -2.50858916 -1.12396307] b_gradient: -1.353519733702093
learningRate: 0.00026472769124323987
iter: 66 cost: 217387963.10227597 m: [0.04121152 0.20789623 1.17611686 0.1358002 ]  b: 0.15750713899660726
m_gradient: [ 1.43900236  4.3480451  -2.4711211  -1.12406495] b_gradient: -1.3535361201381892
learningRate: 0.0002779640758054019
iter: 67 cost: 217330112.92539644 m: [0.04082454 0.20668958 1.17679309 0.13611268]  b: 0.157883377615513
m_gradient: [ 1.39221026  4.34100682 -2.43278061 -1.12416362] b_gradient: -1.353551237927353
learningRate: 0.000291862279595672
iter: 68 cost: 217270142.32037157 m: [0.04043212 0.20542481 1.17749168 0.1364408 ]  b: 0.15827843196657157
m_gradient: [ 1.34452629  4.33344098 -2.39357076 -1.1242582 ] b_gradient: -1.3535642619041839
learningRate: 0.0003064553935754556
iter: 69 cost: 217207991.53882435 m: [0.04003495 0.2040993  1.17821293 0.13678537]  b: 0.15869324237356774
m_gradient: [ 1.29599907  4.32530646 -2.3535339  -1.12434792] b_gradient: -1.3535751554459983
learningRate: 0.0003217781632542284
iter: 70 cost: 217143599.53372645 m: [0.03963379 0.20271032 1.17895711 0.13714718]  b: 0.1591287959778035
m_gradient: [ 1.24669731  4.31656521 -2.31270125 -1.12443184] b_gradient: -1.3535834744995674
learningRate: 0.0003378670714169398
iter: 71 cost: 217076903.8903749 m: [0.03922947 0.20125507 1.17972445 0.13752712]  b: 0.15958612911710554
m_gradient: [ 1.1966905   4.30717407 -2.27111837 -1.12450901] b_gradient: -1.3535889643938361
learningRate: 0.0003547604249877868
iter: 72 cost: 217007840.7605342 m: [0.03882289 0.19973063 1.18051515 0.13792607]  b: 0.16006632970873383
m_gradient: [ 1.1460606   4.29708951 -2.2288304  -1.12457838] b_gradient: -1.353591206360763
learningRate: 0.00037249844623717614
iter: 73 cost: 216936344.8038164 m: [0.03841505 0.19813401 1.18132939 0.138345  ]  b: 0.16057053982752698
m_gradient: [ 1.09489431  4.28626435 -2.18589231 -1.12463884] b_gradient: -1.353589857585898
learningRate: 0.000391123368549035
iter: 74 cost: 216862349.14122936 m: [0.03800699 0.19646209 1.18216732 0.13878489]  b: 0.16109995834195381
m_gradient: [ 1.04328926  4.27465032 -2.14236096 -1.12468917] b_gradient: -1.3535844620863013
learningRate: 0.00041067953697648677
iter: 75 cost: 216785785.32664317 m: [0.03759987 0.1947117  1.18302905 0.1392468 ]  b: 0.16165584373880246
m_gradient: [ 0.99134851  4.26219582 -2.09830216 -1.12472812] b_gradient: -1.3535746166979612
learningRate: 0.00043121351382531114
iter: 76 cost: 216706583.34279662 m: [0.03719488 0.19287953 1.18391467 0.13973181]  b: 0.1622395170185021
m_gradient: [ 0.9391858   4.2488482  -2.05378352 -1.12475431] b_gradient: -1.3535598050298858
learningRate: 0.0004527741895165767
iter: 77 cost: 216624671.62922993 m: [0.0367933  0.19096224 1.18482424 0.14024107]  b: 0.16285236480491322
m_gradient: [ 0.88691938  4.23455133 -2.00888209 -1.12476634] b_gradient: -1.3535395802164827
learningRate: 0.00047541289899240556
iter: 78 cost: 216539977.1502642 m: [0.03639649 0.18895635 1.18575779 0.1407758 ]  b: 0.16349584250580018
m_gradient: [ 0.8346789   4.21924873 -1.96367452 -1.12476268] b_gradient: -1.353513340194918
learningRate: 0.0004991835439420259
iter: 79 cost: 216452425.51171342 m: [0.03600583 0.18685835 1.18671535 0.14133725]  b: 0.16417147776377966
m_gradient: [ 0.78259502  4.20287961 -1.91824963 -1.12474177] b_gradient: -1.353480630879809
learningRate: 0.0005241427211391273
iter: 80 cost: 216361941.13539773 m: [0.03562278 0.18466461 1.18769691 0.14192675]  b: 0.16488087385357253
m_gradient: [ 0.73081349  4.18538504 -1.87268887 -1.12470194] b_gradient: -1.3534406969367572
learningRate: 0.0005503498571960836
iter: 81 cost: 216268447.50067827 m: [0.03524883 0.18237146 1.18870245 0.1425457 ]  b: 0.1656257136133832
m_gradient: [ 0.67947052  4.16669833 -1.8270966  -1.12464152] b_gradient: -1.3533932099219348
learningRate: 0.0005778673500558878
iter: 82 cost: 216171867.46206775 m: [0.0348855  0.17997519 1.18973195 0.14319555]  b: 0.16640776287057846
m_gradient: [ 0.62873381  4.14676264 -1.78154511 -1.12455863] b_gradient: -1.353336984897328
learningRate: 0.0006067607175586823
iter: 83 cost: 216072123.65144405 m: [0.03453436 0.177472   1.19078539 0.14387782]  b: 0.1672288754279087
m_gradient: [ 0.57872113  4.12549779 -1.73617792 -1.12445164] b_gradient: -1.3532724409615813
learningRate: 0.0006370987534366165
iter: 84 cost: 215969138.9724943 m: [0.03419691 0.17485806 1.19186272 0.14459412]  b: 0.1680909952300243
m_gradient: [ 0.52966568  4.10287    -1.69099288 -1.12431826] b_gradient: -1.3531964981334266
learningRate: 0.0006689536911084473
iter: 85 cost: 215862837.19362906 m: [0.03387478 0.17212958 1.19296404 0.14534613]  b: 0.16899616584992572
m_gradient: [ 0.48154106  4.07873645 -1.64632562 -1.12415751] b_gradient: -1.3531140225888605
learningRate: 0.0007024013756638697
iter: 86 cost: 215753143.64381656 m: [0.03356926 0.16928259 1.19408906 0.1461356 ]  b: 0.16994652204835287
m_gradient: [ 0.43496297  4.05322221 -1.60167726 -1.12396505] b_gradient: -1.3530101610762288
learningRate: 0.0007375214444470631
iter: 87 cost: 215639986.01367083 m: [0.03328249 0.16631352 1.19523868 0.14696439]  b: 0.17094433127522357
m_gradient: [ 0.38883759  4.02574099 -1.55876039 -1.12374534] b_gradient: -1.3529223243383626
learningRate: 0.0007743975166694164
iter: 88 cost: 215523295.26327816 m: [0.03301383 0.16321768 1.19641032 0.14783441]  b: 0.1719918889935842
m_gradient: [ 0.34692785  3.99773363 -1.51298092 -1.12347777] b_gradient: -1.3527389949105537
learningRate: 0.0008131173925028872
iter: 89 cost: 215403006.65697014 m: [0.03277139 0.15999411 1.1976129  0.14874772]  b: 0.17309187656842603
m_gradient: [ 0.29816044  3.96445991 -1.47897046 -1.12321805] b_gradient: -1.3528029101135295
learningRate: 0.0008537732621280316
iter: 90 cost: 215279061.22934285 m: [0.03253246 0.15662909 1.19881552 0.14970631]  b: 0.1742461559938533
m_gradient: [ 0.27985349  3.94135766 -1.40859441 -1.12277295] b_gradient: -1.351974202788013
learningRate: 0.0008964619252344332
iter: 91 cost: 215151412.2156477 m: [0.03238854 0.15315663 1.20013562 0.15071287]  b: 0.17546021918515334
m_gradient: [ 0.16053621  3.87350767 -1.47256839 -1.12281731] b_gradient: -1.354283051098415
learningRate: 0.0009412850214961549
iter: 92 cost: 215020110.77707818 m: [0.03197729 0.14942174 1.20110235 0.15176786]  b: 0.17672579306561667
m_gradient: [ 0.43690283  3.96786319 -1.02703461 -1.12079521] b_gradient: -1.3445171776469171
learningRate: 0.0009883492725709627
iter: 93 cost: 214886834.45480567 m: [0.03285413 0.14606907 1.20373194 0.1528817 ]  b: 0.17809349503891306
m_gradient: [-0.88717698  3.39219637 -2.66058326 -1.12697164] b_gradient: -1.3838245357722723
learningRate: 0.001037766736199511
iter: 94 cost: 214785875.8696739 m: [0.02794612 0.14014656 1.19885238 0.15402057]  b: 0.17934978858100953
m_gradient: [ 4.72939817  5.70697244  4.70198342 -1.09741712] b_gradient: -1.2105741090692967
learningRate: 0.0010896550730094866
iter: 95 cost: 215489406.8568359 m: [0.05145682 0.14590949 1.23081572 0.15536303]  b: 0.18154568622885486
m_gradient: [-21.57627293  -5.2887597  -29.3334494   -1.23200747] b_gradient: -2.0152227087610006
learningRate: 0.0005448275365047433
iter: 96 cost: 236500115.38412863 m: [-0.00744451  0.11935392  1.15513716  0.15567046]  b: 0.18047866689331207
m_gradient: [108.11003938  48.74122447 138.90370581  -0.56427246] b_gradient: 1.9584533894672425
learningRate: 0.00027241376825237165
iter: 97 cost: 301972053.54359514 m: [0.05121182 0.14281017 1.23153857 0.15627722]  b: 0.18264393112478114
m_gradient: [-215.32071841  -86.10522605 -280.46090379   -2.2273504 ] b_gradient: -7.9484390431511045
learningRate: 0.00013620688412618583
iter: 98 cost: 235954238.72780445 m: [0.03663597 0.1362371  1.21280634 0.15635477]  b: 0.18238165463767822
m_gradient: [107.01258454  48.2580156  137.52779599  -0.56936022] b_gradient: 1.9255743847714863
learningRate: 0.0001430172283324951
iter: 99 cost: 215699489.03586492 m: [0.03277976 0.13410854 1.20798176 0.15649507]  b: 0.1824569383709204
m_gradient: [26.96321558 14.88326329 33.73420568 -0.98097231] b_gradient: -0.5263962539334458
learningRate: 0.00015016808974911987
iter: 100 cost: 214375328.3856955 m: [0.03190761 0.13319858 1.20703428 0.1566587 ]  b: 0.18263328226775874
m_gradient: [ 5.80785278  6.05957104  6.3094625  -1.08967977] b_gradient: -1.1743100490454148
learningRate: 0.00015767649423657586
